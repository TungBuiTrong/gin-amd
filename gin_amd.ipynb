{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "25XiE3Rfb5AR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from torch_geometric.nn import Linear, BatchNorm, GINEConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OHbjkhyNmvh"
   },
   "outputs": [],
   "source": [
    "class StarGIN(torch.nn.Module):\n",
    "    def __init__(self, num_features = 5, num_gnn_layers = 1, n_classes=36, n_hidden=64, edge_updates=True, edge_dim=77, dropout=0.0, final_dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.num_gnn_layers = num_gnn_layers\n",
    "        self.edge_updates = edge_updates\n",
    "        self.dropout = dropout\n",
    "        self.final_dropout = final_dropout\n",
    "\n",
    "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
    "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "              \n",
    "        for _ in range(self.num_gnn_layers):\n",
    "            conv = GINEConv(nn.Sequential(\n",
    "                nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                nn.BatchNorm1d(n_hidden),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                nn.BatchNorm1d(n_hidden),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.ReLU(),\n",
    "                ), edge_dim=self.n_hidden)\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        self.mlp = nn.Sequential(Linear(n_hidden, n_hidden), nn.ReLU(), nn.Dropout(self.dropout))\n",
    "        self.layer_pool = Linear(n_hidden, n_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        device = x.device\n",
    "        src, dst = edge_index\n",
    "        x = self.node_emb(x).to(device)\n",
    "        edge_attr = self.edge_emb(edge_attr).to(device)\n",
    "\n",
    "        for i in range(self.num_gnn_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        x_mean = global_mean_pool(x, batch)\n",
    "        output = self.layer_pool(x_mean)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkKUjUF8Nmvj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0.0 \n",
    "    num_batches = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    return average_loss\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = torch.tensor([], dtype=torch.long, device=\"cpu\")\n",
    "    all_labels = torch.tensor([], dtype=torch.long, device=\"cpu\")\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "      for data in loader:   \n",
    "        data = data.to(device)    \n",
    "        output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        preds = output.argmax(dim=1)\n",
    "        target = data.y.view(-1)\n",
    "        if target.dim() == 0:\n",
    "            target = target.unsqueeze(0)\n",
    "        all_preds = torch.cat((all_preds, preds.cpu()), dim=0)\n",
    "        all_labels = torch.cat((all_labels, target.cpu()), dim=0)\n",
    "\n",
    "        loss = criterion(output, data.y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    average_loss = total_loss / len(loader)\n",
    "    \n",
    "    all_preds_np = all_preds.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    cm = confusion_matrix(all_labels_np, all_preds_np)\n",
    "\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"accuracy\": [accuracy_score(all_labels_np, all_preds_np)],\n",
    "        \"macro_precision\": [precision_score(all_labels_np, all_preds_np, average='macro', zero_division=0)],\n",
    "        \"macro_recall\": [recall_score(all_labels_np, all_preds_np, average='macro', zero_division=0)],\n",
    "        \"macro_f1\": [f1_score(all_labels_np, all_preds_np, average='macro', zero_division=0)],\n",
    "        \"micro_precision\": [precision_score(all_labels_np, all_preds_np, average='micro', zero_division=0)],\n",
    "        \"micro_recall\": [recall_score(all_labels_np, all_preds_np, average='micro', zero_division=0)],\n",
    "        \"micro_f1\": [f1_score(all_labels_np, all_preds_np, average='micro', zero_division=0)],\n",
    "        \"weighted_precision\": [precision_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)],\n",
    "        \"weighted_recall\": [recall_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)],\n",
    "        \"weighted_f1\": [f1_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)],\n",
    "    })\n",
    "\n",
    "\n",
    "    return metrics_df, cm, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxmCDy0FzMF5",
    "outputId": "a405f86b-52d1-4ec2-b14c-91f2e5d18877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data input model successful !\n"
     ]
    }
   ],
   "source": [
    "pyg_file = r'C:\\Users\\LEENT\\Desktop\\CICandMal17\\Graph\\cat_full_graph_data.pt'\n",
    "list_data = torch.load(pyg_file,  weights_only=False)\n",
    "labels = []\n",
    "for data in list_data:\n",
    "    labels.extend(data.y.tolist())\n",
    "\n",
    "\n",
    "print('Prepare data input model successful !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjmUyEtQJu4s"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "label_counts = Counter(labels)\n",
    "sorted_counts = dict(sorted(label_counts.items())) \n",
    "\n",
    "\n",
    "total_samples = len(labels)\n",
    "total_samples = len(labels)\n",
    "class_weights = torch.tensor(\n",
    "    [total_samples / label_counts[label] for label in sorted(label_counts.keys())],\n",
    "    dtype=torch.float\n",
    ").to(device)\n",
    "\n",
    "for label, weight in enumerate(class_weights):\n",
    "    print(f\"Class {label}: count = {sorted_counts[label]}, weight = {weight:.4f}\")\n",
    "\n",
    "lr = 0.001\n",
    "h_layers = 64\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_data(data_list, ratio=0.2, seed=42):\n",
    "   \n",
    "    rng = random.Random(seed)\n",
    "    \n",
    "    family_dict = defaultdict(list)\n",
    "    for data in data_list:\n",
    "        fam = data.y.item() if hasattr(data.y, \"item\") else int(data.y)\n",
    "        family_dict[fam].append(data)\n",
    "\n",
    "    \n",
    "    min_count = min(len(samples) for samples in family_dict.values())\n",
    "    if min_count == 0:\n",
    "        \n",
    "        return [], data_list[:]\n",
    "\n",
    "    k_test = int(min_count * ratio)\n",
    "    k_train = min_count - k_test\n",
    "\n",
    "    if k_test == 0 and min_count >= 2:\n",
    "        k_test, k_train = 1, min_count - 1\n",
    "\n",
    "    sublist_1, sublist_2 = [], []\n",
    "\n",
    "    for fam, samples in family_dict.items():\n",
    "        \n",
    "        rng.shuffle(samples)\n",
    "        \n",
    "        chosen = samples[:min_count]\n",
    "        test_part  = chosen[:k_test]\n",
    "        train_part = chosen[k_test:k_test + k_train]\n",
    "\n",
    "        sublist_1.extend(test_part)\n",
    "        sublist_2.extend(train_part)\n",
    "\n",
    "    return sublist_1, sublist_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv90hVvoDmjA",
    "outputId": "91b551f2-96ab-4bb8-e3ba-3455a4e6264f"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import pynvml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader  \n",
    "\n",
    "def get_resource_info(gpu_index=0):\n",
    "    cpu_percent = psutil.cpu_percent(interval=None)\n",
    "\n",
    "   \n",
    "    process = psutil.Process(os.getpid())\n",
    "    ram_process_kb = int(process.memory_info().rss // 1024)\n",
    "\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_index)\n",
    "    \n",
    "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    vram_used_kb = int(mem_info.used // 1024)\n",
    "\n",
    "    gpu_util_percent = float(pynvml.nvmlDeviceGetUtilizationRates(handle).gpu)\n",
    "    \n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "    return cpu_percent, ram_process_kb, vram_used_kb, gpu_util_percent\n",
    "\n",
    "\n",
    "\n",
    "def shorten_pyg_name(path: str) -> str:\n",
    "    name = os.path.basename(path)\n",
    "    return name\n",
    "\n",
    "\n",
    "def save_csv(dataframe: pd.DataFrame, filepath: str):\n",
    "    if not os.path.isfile(filepath):\n",
    "        dataframe.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        dataframe.to_csv(filepath, mode=\"a\", header=False, index=False)\n",
    "\n",
    "\n",
    "def append_row_csv(row_dict: dict, filepath: str):\n",
    "    df = pd.DataFrame([row_dict])\n",
    "    if not os.path.isfile(filepath):\n",
    "        df.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        df.to_csv(filepath, mode=\"a\", header=False, index=False)\n",
    "\n",
    "\n",
    "\n",
    "results_dir = f\"C:/Users/LEENT/Desktop/CICandMal17/Results/2_layer/CAT_LR{lr}and{h_layers}/\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "mac_results     = f\"{results_dir}classification_5d_macro_LR{lr}and{h_layers}.csv\"\n",
    "mic_results     = f\"{results_dir}classification_5d_micro_LR{lr}and{h_layers}.csv\"\n",
    "w_results       = f\"{results_dir}classification_5d_weight_LR{lr}and{h_layers}.csv\"\n",
    "mac_cm_results  = f\"{results_dir}classification_5d_macro_cm_LR{lr}and{h_layers}.csv\"\n",
    "mic_cm_results  = f\"{results_dir}classification_5d_micro_cm_LR{lr}and{h_layers}.csv\"\n",
    "w_cm_results    = f\"{results_dir}classification_5d_weight_cm_LR{lr}and{h_layers}.csv\"\n",
    "\n",
    "resource_csv    = f\"{results_dir}resource_usage_LR{lr}and{h_layers}.csv\"\n",
    "\n",
    "pyg_name_for_csv = shorten_pyg_name(pyg_file)  \n",
    "\n",
    "test_data, remain_data = split_data(list_data, 0.2)\n",
    "remain_labels = []\n",
    "for d in remain_data:\n",
    "    remain_labels.extend(d.y.tolist())\n",
    "\n",
    "for i in range(2):\n",
    "    model = StarGIN(num_features=127, n_classes=5, num_gnn_layers = 2,  n_hidden=h_layers, edge_updates=False, dropout=0.5)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "    temp_data, not_use_data = train_test_split(remain_data, test_size=0.2, random_state=42, stratify=remain_labels)\n",
    "\n",
    "    train_loader = DataLoader(temp_data, batch_size=32, shuffle=True)\n",
    "    test_loader  = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    total_loss_epochs = 0.0\n",
    "\n",
    "    train_metrics = pd.DataFrame()\n",
    "    test_metrics  = pd.DataFrame()\n",
    "\n",
    "    mac_f1_final = 0.0\n",
    "    mac_final_cm = pd.DataFrame()\n",
    "    mac_final_metrics = pd.DataFrame()\n",
    "\n",
    "    mic_f1_final = 0.0\n",
    "    mic_final_cm = pd.DataFrame()\n",
    "    mic_final_metrics = pd.DataFrame()\n",
    "\n",
    "    w_f1_final = 0.0\n",
    "    w_final_cm = pd.DataFrame()\n",
    "    w_final_metrics = pd.DataFrame()\n",
    "\n",
    "    train_time = 0.0\n",
    "    test_time  = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        cpu_b, ram_proc_b, vram_b, gpu_b = get_resource_info(gpu_index=0)\n",
    "\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        train_metrics, _, _ = evaluate(model, train_loader, criterion, device)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        train_time += int(1000 * (end - start))  # ms\n",
    "\n",
    "        cpu_a, ram_proc_a, vram_a, gpu_a = get_resource_info(gpu_index=0)\n",
    "\n",
    "        \n",
    "        cpu_delta = cpu_a - cpu_b                     # %\n",
    "        ram_kb_delta = ram_proc_a - ram_proc_b        # KB\n",
    "        vram_kb_delta = vram_a - vram_b               # KB\n",
    "        gpu_delta = gpu_a - gpu_b                     # %\n",
    "\n",
    "        print(f\"[TRAIN]  CPU: {cpu_delta:.2f} % | RAM: {ram_kb_delta:.0f} KB | \"\n",
    "            f\"VRAM: {vram_kb_delta:.0f} KB | GPU Usage: {gpu_delta:.2f} %\")\n",
    "\n",
    "\n",
    "        \n",
    "        row_train = {\n",
    "            \"run_index\": i,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"phase\": \"train\",\n",
    "            \"file_name\": pyg_name_for_csv,\n",
    "            \"cpu_used_percent_delta\": cpu_delta,\n",
    "            \"ram_used_process_kb_delta\": ram_kb_delta,\n",
    "            \"vram_used\": vram_kb_delta,\n",
    "            \"gpu_used_percent_delta\": gpu_delta,\n",
    "            \"elapsed_train_time_ms_cum\": train_time,\n",
    "        }\n",
    "        append_row_csv(row_train, resource_csv)\n",
    "\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        cpu_b_t, ram_proc_b_t, vram_b_t, gpu_b_t = get_resource_info(gpu_index=0)\n",
    "\n",
    "        test_metrics, cm, test_loss = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        test_time += int(1000 * (end - start))  # ms\n",
    "\n",
    "        cpu_a_t, ram_proc_a_t, vram_a_t, gpu_a_t = get_resource_info(gpu_index=0)\n",
    "\n",
    "        cpu_delta_t = cpu_a_t - cpu_b_t                     # %\n",
    "        ram_kb_delta_t = ram_proc_a_t - ram_proc_b_t        # KB\n",
    "        vram_kb_delta_t = vram_a_t - vram_b_t               # KB\n",
    "        gpu_delta_t = gpu_a_t - gpu_b_t                     # %\n",
    "\n",
    "        print(f\"[TEST]  CPU: {cpu_delta_t:.2f} % | RAM: {ram_kb_delta_t:.0f} KB | \"\n",
    "            f\"VRAM: {vram_kb_delta_t:.0f} KB | GPU Usage: {gpu_delta_t:.2f} %\")\n",
    "\n",
    "        \n",
    "        row_test = {\n",
    "            \"run_index\": i,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"phase\": \"test\",\n",
    "            \"file_name\": pyg_name_for_csv,\n",
    "            \"cpu_used_percent_delta\": cpu_delta_t,\n",
    "            \"ram_used_process_kb_delta\": ram_kb_delta_t,   \n",
    "            \"vram_used\": vram_kb_delta_t,\n",
    "            \"gpu_used_percent_delta\": gpu_delta_t,\n",
    "            \"elapsed_test_time_ms_cum\": test_time,\n",
    "        }\n",
    "        append_row_csv(row_test, resource_csv)\n",
    "\n",
    "\n",
    "        df_cm = pd.DataFrame(cm, index=range(5), columns=range(5))\n",
    "        total_loss_epochs += test_loss\n",
    "\n",
    "        if mac_f1_final < test_metrics[\"macro_f1\"].iloc[0]:\n",
    "            mac_f1_final = test_metrics[\"macro_f1\"].iloc[0]\n",
    "            mac_final_metrics = test_metrics\n",
    "            mac_final_cm = df_cm\n",
    "\n",
    "        if w_f1_final < test_metrics[\"weighted_f1\"].iloc[0]:\n",
    "            w_f1_final = test_metrics[\"weighted_f1\"].iloc[0]\n",
    "            w_final_metrics = test_metrics\n",
    "            w_final_cm = df_cm\n",
    "\n",
    "        if mic_f1_final < test_metrics[\"micro_f1\"].iloc[0]:\n",
    "            mic_f1_final = test_metrics[\"micro_f1\"].iloc[0]\n",
    "            mic_final_metrics = test_metrics\n",
    "            mic_final_cm = df_cm\n",
    "\n",
    "    for m in [mac_final_metrics, mic_final_metrics, w_final_metrics]:\n",
    "        m[\"elapsed_time\"] = train_time\n",
    "        m[\"test_time\"] = test_time\n",
    "        m[\"experiment\"] = \"GINv11\"\n",
    "        m[\"file_name\"] = pyg_name_for_csv\n",
    "\n",
    "    save_csv(mac_final_metrics, mac_results)\n",
    "    save_csv(mic_final_metrics, mic_results)\n",
    "    save_csv(w_final_metrics, w_results)\n",
    "    save_csv(mac_final_cm, mac_cm_results)\n",
    "    save_csv(mic_final_cm, mic_cm_results)\n",
    "    save_csv(w_final_cm, w_cm_results)\n",
    "\n",
    "\n",
    "    print(f\"Loss average: {total_loss_epochs / epochs:.6f}\")\n",
    "    print(f\"Train accuracy: {train_metrics['accuracy'].iloc[0] * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\nBest model based on macro:\")\n",
    "    print(f\"Accuracy: {mac_final_metrics['accuracy'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Recall: {mac_final_metrics['macro_recall'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Precision: {mac_final_metrics['macro_precision'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"F1: {mac_final_metrics['macro_f1'].iloc[0] * 100:.2f}%\")\n",
    "    print(mac_final_cm)\n",
    "\n",
    "    print(\"\\nBest model based on weighted:\")\n",
    "    print(f\"Accuracy: {w_final_metrics['accuracy'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Recall: {w_final_metrics['weighted_recall'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Precision: {w_final_metrics['weighted_precision'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"F1: {w_final_metrics['weighted_f1'].iloc[0] * 100:.2f}%\")\n",
    "    print(w_final_cm)\n",
    "\n",
    "    print(\"\\nBest model based on micro:\")\n",
    "    print(f\"Accuracy: {mic_final_metrics['accuracy'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Recall: {mic_final_metrics['micro_recall'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"Precision: {mic_final_metrics['micro_precision'].iloc[0] * 100:.2f}% | \"\n",
    "          f\"F1: {mic_final_metrics['micro_f1'].iloc[0] * 100:.2f}%\")\n",
    "    print(mic_final_cm)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
